---
title: "Statistics II"
author: "
<table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'><col width='10%'><col width='10%'>
  <tr style='border:none'>
    <td style='display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none' nowrap>
      <font style='font-style:normal'>Introduction to R</font><br>
      <a href='https://dwulff.github.io/Intro2R_Unibe/'>
        <i class='fas fa-clock' style='font-size:.9em;' ></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <i class='fas fa-home' style='font-size:.9em;'></i>
      </a>
      <a href='mailto:therbootcamp@gmail.com'>
        <i class='fas fa-envelope' style='font-size: .9em;'></i>
      </a>
      <a href='https://www.linkedin.com/company/basel-r-bootcamp/'>
        <i class='fab fa-linkedin' style='font-size: .9em;'></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <font style='font-style:normal'>Bern R Bootcamp</font>
      </a>
    </td>
    <td style='width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none'>
      <img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
    </td>
  </tr>
</table>"
output:
  html_document:
    css: practical.css
    self_contained: no
---

```{r setup, echo = FALSE, warning=F, message=F}
knitr::opts_chunk$set(comment = NA, 
                      fig.width = 6, 
                      fig.height = 6,
                      fig.align = 'center',
                      echo = FALSE, 
                      eval = FALSE, 
                      warning = FALSE,
                      message = FALSE)
options(digits = 3)
```

<p align="center">
<img width="100%" src="image/hansrosling.png" margin=0><br>
<font style="font-size:10px">from [TED.com](https://www.ted.com/talks/hans_rosling_the_truth_about_hiv)</font>
</p>

# {.tabset}


## Overview

In this practical you'll do basic statistics in R. By the end of this practical you will know how to:

1. Run regression analyses with `glm()` and `lm()`.
2. Evaluate and explore statistical objects with `summary()`, `anova()`, and `names()`.
3. Run mixed-model and Bayesian regressions using the `lme4` and `BayesFactor` packages.


## Tasks

```{r, echo = FALSE, eval = TRUE, include = FALSE}

library(BayesFactor)
library(lme4)
library(rsq)
library(tidyverse)

gap <- read_csv("1_Data/gap.csv")

```


### A - Getting setup

1. Open your `BernRBootcamp` R project. It should already have the folders `1_Data` and `2_Code`. Make sure that all of the data files listed in the `Datasets` section are contained in the `1_Data` folder.

```{r}
# Done!
```

2. Open a new R script and save it as a new file called `statisticsII_practical.R` in the `2_Code` folder. At the top of the script, using comments, write your name and the date. The, load the set of packages listed in the `Functions` section with `library()`.

3. For this practical, we'll use the `gap.csv` data. This dataset contains data from three years on economic and health variables of 139 countries. Using the following template, load the data into R and store it as a new object called `gap`.

```{r, echo = TRUE, eval = FALSE}
gap <- read_csv(file = "XX")
```

```{r}
gap <- read_csv(file = "1_Data/gap.csv")
```

4. Using `print()`, `summary()`, and `head()`, explore the data to make sure it was loaded correctly.

```{r}
gap
summary(gap)
head(gap)
```

### B - Regression models with `lm()`

1. To begin with, evaluate the relationship between the health expenditure of the country (`healthExp`) and child mortality (`childMort`) using a regression with child mortality as the criterion and health expenditure as the predictor. Simply complete the code below.

```{r, eval = FALSE, echo = TRUE}
mort_lm <- lm(formula = XX ~ XX,
              data = XX)
```


```{r}
mort_lm <- lm(formula = childMort ~ healthExp,
              data = gap)
```

2. Print your `mort_lm` object to see the main results.

```{r}
mort_lm
```


3. Use the `summary()` function to return a data frame containing the main results of the linear regression. Evaluate the test results: Does health expenditure significantly predict child mortality? How much variance is explained by health expenditure (Tip: look for Multiple R-squared)?

```{r}
summary(mort_lm)
```

4. You probably concluded correctly that health expenditure correctly predicts child mortality. One way to confirm this is via a simple plot by plugging the two variables into the code below (don't worry you learn how to do fancier plots in the next sessions).

```{r, echo = TRUE, eval = FALSE}
plot(gap$XX, gap$XX, log = "xy")
```

```{r}
plot(gap$healthExp, gap$childMort, log = "xy")
```

5. Health expenditure is strongly related to child mortality, but is it the best predictor. Run the regression again, this time adding the GDP per capita (`gdpPercap`) as a second predictor.

```{r, eval = FALSE, echo = TRUE}
mort_lm <- lm(formula = XX ~ XX + XX,
              data = XX)
```

```{r}
mort_lm <- lm(formula = childMort ~ healthExp + gdpPercap,
              data = gap)
```

6. Have the results changed? Which predictor is more strongly related to child mortality? Evaluate using `summary()`.  

```{r}
summary(mort_lm)
```

7. GDP per capita is the better predictor of child mortality. Now play around a bit. Find out if the two predictors interact or whether any of the other `numeric` (!) variables significantly improve the prediction of child mortality.

### C - AN(C)OVA models with `lm()`

1. ANOVAs in R are also run using `lm()`. Technically, an ANOVA is a regression using dummy variables to code each of the predictor levels in the ANOVA. To see this, predict child mortality using `continent` and print the resulting model.

```{r, eval = FALSE, echo = TRUE}
mort_anova <- lm(formula = XX ~ continent,
                 data = XX)
mort_anova
```

```{r}
mort_anova <- lm(formula = childMort ~ continent,
                 data = gap)
mort_anova
```

2. You should have observed that the model included four predictors, one for each value of `continent` except the first (`Africa`), which in this case is represented by the intercept (`(Intercept)`). Running an ANOVA we are, of course, usually interested in the main effect of the variable `continent` rather than that of the individual levels of the `continent` variable. To get the main effect and a typical ANOVA output, simply apply the `anova()` function to the linear model object. 

```{r, eval = FALSE, echo = TRUE}
mort_anova <- lm(formula = XX ~ continent,
                 data = XX)
anova(mort_anova)
```

```{r}
mort_anova <- lm(formula = childMort ~ continent,
                 data = gap)
anova(mort_anova)
```

3. Interested in evaluating a main effect while accounting for another continuous variable, i.e., to run an ANCOVA? Simply add continuous predictors to the formula. Predict child mortality by continent and GDP per capita and apply the `anova()` function.

```{r}
mort_anova <- lm(formula = childMort ~ continent + gdpPercap,
                 data = gap)
anova(mort_anova)
```

### D - Logistic regression using `glm()`

Logistic regressions (and regular regressions) can be run using `glm()`, R's general linear model function. It works just like the regular `lm()` function, adding only a `family` argument that specifies the probabilistic function linking the predictors and the criterion. For logistic regression this is `family = 'binomial'` to specify a logistic link function.   

1. Prior running a logistic regression, you will have to create your criterion, as there is currently no categorical, two-valued (binary) variable included in the dataset. Create a variable called `co2_largermed` in the `gap` dataset that carries a `1` if CO2 emissions per person are higher than the median value of that variable and `0` if they are smaller or equal. (Tip: Use `mutate()`, `case_when()`, and `median(x, na.rm = TRUE)`).

```{r}
gap <- gap %>%
  mutate(co2_largermed = case_when(
    co2Emit > median(co2Emit, na.rm=T) ~ 1,
    co2Emit <= median(co2Emit, na.rm=T) ~ 0
  ))
```

2. Now run a logistic regression predicting `co2_largermed` using population (`pop`) and GDP per capita (`gdpPercap`) and evaluate the result using `summary()`. See code below. (Note: Don't worry about the warning, if you receive one)

```{r, echo = TRUE, eval = FALSE}
co2_glm <- glm(formula = co2_largermed ~ XX + XX,
               data = XX,
               family = "XX")
summary(co2_glm)
```

```{r}
co2_glm <- glm(formula = co2_largermed ~ pop + gdpPercap,
               data = gap,
               family = "binomial")
summary(co2_glm)
```

3. Not very surprisingly, both high population (`pop`) and high GDP per capita (`gdpPercap`) seem to be associated with higher than median CO2 emission. However, it is possible that the interaction of the two variables is driving the effect, i.e., that CO2 emissions are large only for countries with high GDP per capita *and* high population. Test this by also including the interaction effect via `var_1 * var_2`.   

```{r}
co2_glm <- glm(formula = co2_largermed ~ pop * gdpPercap,
               data = gap,
               family = "binomial")
summary(co2_glm)
```

4. Indeed, it seems that interaction is most important for the prediction of CO2 emissions. But again there is a caveat. By default R implements the interaction of two predictors using their uncentered product as the interaction term. As a result the interaction term will be highly correlated with the original predictors, rendering it difficult to interpret the results. To deal with this issue, create new, centered versions of `pop` and `gdpPercap` called `pop_cent` and `gdpPercap_cent` using `mutate()` and `scale(scale = FALSE)`.

```{r}
gap <- gap %>%
  mutate(pop_cent = scale(pop, scale = FALSE),
         gdpPercap_cent = scale(gdpPercap, scale = FALSE))
```

5. Now, evaluate the model formula `co2_largermed ~ pop + gdpPercap + pop_scaled:gdpPercap_scaled`, which implements the interaction of the scaled and centered variables, (i.e., run the logistic regression with the above formula and apply `summary()`).

```{r}
co2_glm <- glm(formula = co2_largermed ~ pop + gdpPercap +      
               pop_cent:gdpPercap_cent,
               data = gap,
               family = "binomial")
summary(co2_glm)
```

6. All three, the two variables and their interaction, significantly predict higher than median CO2 emissions. This was obscured before because of the inter-correlation between the predictors. If you like, you can confirm that both models, with centered and uncentered interactions, predict the criterion equally well using `rsq()` from the `rsq` package. The `rsq()` function computes the overall R-squared value for generalized linear models. 

```{r, echo = TRUE}
co2_cent_glm <- glm(formula = co2_largermed ~ pop + gdpPercap +      
                    pop_cent:gdpPercap_cent,
                    data = gap,
                    family = "binomial")

co2_noncent_glm <- glm(formula = co2_largermed ~ pop * gdpPercap,
                       data = gap,
                       family = "binomial")


rsq(co2_cent_glm)
rsq(co2_noncent_glm)
```

### E - Working with statistical objects

1. Statistical objects as returned from `lm()` and `glm()` contain a lot of result objects. To see those, inspect the final `mort_lm` object of section B using `names()`.

```{r, eval = FALSE, echo = TRUE}
names(XX)
```

```{r}
names(mort_lm)
```

2. The `lm` object includes among others objects the vector of residuals, i.e., the error committed in predicting each point of the criterion. Using the residuals central assumptions of a regression can be tested, namely that the true relationship is linear and that error variance is of equal size across the entire predictor space.
  Evaluate the two assumptions by plotting the residuals (y-axis) onto the fitted values (x-axis). If both assumptions are true, then the residuals should scatter equally broad across the range of fitted values with an average of roughly zero.

```{r, eval = FALSE, echo = TRUE}
plot(mort_lm$XX, mort_lm$XX)
```

```{r}
plot(mort_lm$fitted.values, mort_lm$residuals)
```

3. Obviously the assumptions are not met. The reason for this is largely that all three variables are extremely right-skewed. Deal with this by rerunning the model with log-transformed versions of all three variables (see below). Recreate the plot. Has anything changed? Assumptions met?

```{r, eval = FALSE, echo = TRUE}
mort_lm <- lm(formula = log(XX) ~ log(XX) + log(XX),
              data = XX)
```

```{r}
mort_lm <- lm(formula = log(childMort) ~ log(healthExp) + log(gdpPercap),
              data = gap)

plot(mort_lm$fitted.values, mort_lm$residuals)
```


### F - Mixed-effects models

So far we have ignored the fact that there were three measurements for each country and that those data should be modeled as repeated measurements. One way to do this is via linear mixed-effects models. 

1. Specify a repeated measurement model by including a random intercept for countries in a regression model predicting child mortality with GDP per capita. See the code below. (Note: Ignore the warning, if you receive one)

```{r, eval = FALSE, echo = TRUE}
mort_lmer <- lmer(formula = childMort ~ gdpPercap + (1|country),
                  data = gap)
```

```{r}
mort_lmer <- lmer(formula = childMort ~ gdpPercap + (1|country),
                  data = gap)
```

2. Print `mort_lmer` and evaluate using `summary()`. Notice any difference to the typical `lm()` outputs?

```{r}
mort_lmer
summary(mort_lmer)
```

There are, at least, two important observations. First, there are no p-values associated with the t-values, which is due to the fact that mixed-effects models require complex adjustments for the degrees of freedom required to determine p-values. Second, there are two sections of effects, random and fixed. The random effects refer to the ones estimated on the country level, whereas the fixed effects refer to ones estimated irrespective of country. 

3. When running mixed-effects models it is recommended to evaluate, whether the inclusion of random effects is indicated, i.e., delivers a substantially better fit to the data. To test this, you can use `anova()` compare the `mort_lmer` to the standard `lm()` model predicting child mortality with GDP per capita. A significant result will indicate that the model without random intercepts is significantly worse than the model with random intercepts.

```{r}
# standard lm
mort_lm <- lm(formula = childMort ~ gdpPercap,
              data = gap)

# compare with anova
anova(mort_lmer, mort_lm)
```

### G - Bayesian models

Finally, let us turn to new (old) kid in town, Bayesian statistics. With today's computing power, long existing Bayesian statistics have become a viable alternative for practically all *Frequentist* (i.e., classic) analysis approaches. In R, Bayesian methods for linear models have been made available among others through the `BayesFactor` package. 

1. Run a Bayesian regression using the `regressionBF` function of the `BayesFactor` package predicting child mortality using GDP per capita. (Note: Contrary to other functions `regressionBF()` and other `BayesFactor` functions require that NAs are removed beforehand).

```{r, eval = FALSE, echo = TRUE}
# Bayesian lm
mort_blm <- regressionBF(formula = childMort ~ gdpPercap,
                         data = gap %>% 
                         filter(!is.na(childMort)))

```

```{r}
# Bayesian lm
mort_blm <- regressionBF(formula = childMort ~ gdpPercap,
                         data = gap %>% filter(!is.na(childMort)))

```

2. Evaluate `mort_blm` by printing it. You'll see a very different output showing only the BayesFactor, a metric specifying the amount of evidence in the data against the hypothesis of the predictor having no effect on the criterion.

```{r}
mort_blm
```

3. What is missing from the output are the actual estimates for the predictor. To extract those, you need to sample from the posterior distribution and then average across the samples.  

```{r, eval = FALSE, echo = TRUE}
# sample from posterior
post <- posterior(mort_blm, iterations = 1000)

# get estimates
colMeans(as.matrix(post))
```

```{r}
# sample from posterior
post <- posterior(mort_blm, iterations = 1000)

# get estimates
colMeans(as.matrix(post))
```

4. Compare the estimate of the effect of GDP per capita on child mortality from the Bayesian method to the one from the standard `lm()`. How similar are they? 

## Examples

```{r, eval = FALSE, echo = TRUE, message = FALSE, warning = FALSE}

# Examples of regression models on the diamonds dataset -------------

library(tidyverse)
library(broom)
library(BayesFactor)
library(lme4)

# First few rows of the diamonds data

diamonds

# Regression ----------------------------

# Q: Run regression predicting price by carat and depth

price_lm <- lm(formula = price ~ carat + depth,
               data = diamonds)

# Print coefficients
price_lm$coefficients

# Regular summary
summary(price_lm)

# Tidy version
tidy(price_lm)


# Q: Run regression predicting price by carat and depth and their interaction

price_lm <- lm(formula = price ~ carat * depth,
               data = diamonds)

# Print coefficients
price_lm$coefficients

# Regular summary
summary(price_lm)

# Tidy version
tidy(price_lm)


# ANOVA ----------------------------

# Q: Run ANOVA predicting price by color and cut

# transform to factor
dimaonds$cut = as.factor(diamonds$cut)
dimaonds$color = as.factor(dimaonds$color)

# Run model
price_lm <- lm(formula = price ~ cut + color,
               data = diamonds)

# Print coefficients
price_lm$coefficients

# Regular summary
summary(price_lm)

# Tidy version
tidy(price_lm)

# ANOVA version
anova(price_lm)

# Mixed-effects regression ----------------------------

# Q: Run mixed-effect regression predicting carat and depth with the impact of carat varying across color.

# Run model
price_lme <- lmer(formula = price ~ carat + depth + (1 + carat|color),
                  data = diamonds)

# Regular summary
summary(price_lme)


# Bayesian regression ----------------------------

# Q: Run Bayesian regression predicting carat and depth

# Run model
price_Blm <- regressionBF(formula = price ~ carat + depth,
                  data = diamonds)

# Regular summary
price_Blm


```

## Datasets

|File | Rows | Columns | Description |
|:----|:-----|:------|:-----------------------------------------|
|[gap.csv](https://raw.githubusercontent.com/therbootcamp/Intro2R_Unibe/master/_sessions/StatisticsII/1_Data/gap.csv) | 417 | 9 | Country statistics from 1997, 2002, and 2007 from the Gapminder Foundation. |

The Gapminder Foundation is a non-profit venture registered in Stockholm, Sweden, that promotes sustainable global development and achievement of the United Nations Millennium Development Goals by increased use and understanding of statistics and other information about social, economic and environmental development at local, national and global levels (see [Gapminder.org](https://www.gapminder.org)). The present dataset is an excerpt of their database holding data from three years on economic and health variables of 139 countries.


|Variable | Description |
|:-------------|:-------------------------------------|
|country| country name|
|continent| country's continent|
|year| measurement year|
|lifeExp| life expectancy at birth, in years |
|pop| country's population|
|gdpPercap| country's GDP per capita (US$)|
|childMort| child mortality (0-5 year-olds dying per 1,000 born)|
|co2Emit| CO2 emissions (tonnes per person) |
|healthExp| Government health spending per person (international $)|

## Functions

### Packages

|Package| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|
|`rsq`|`install.packages("rsq")`|
|`lme4`|`install.packages("lme4")`|
|`BayesFactor`|`install.packages("BayesFactor")`|

### Functions

*Model functions*

| Function| Package | Description |
|:------|:-------------------|:-------------------|
|     `lm()`, `glm()`|  `stats`  |  (Generalized) linear models |
|     `lmer()`, `glmer()` | `lme4` | (Generalized) linear mixed-effects models |
|     `regressionBF()`, `lmBF()`| `BayesFactor` | Bayesian (generalized, mixed-effects) linear models |

*Inspect models*

| Function| Package | Description |
|:------|:-------------------|:-------------------|
|     `print()`|  `base`  | Standard printout |
|     `summary()`|  `base`  |  Standard model evaluation |
|     `anova()`|  `stats`  | ANOVA model evaluation and model comparison |
|     `names()` | `base` | Print names of objects contained in model output  |

## Resources

### Documentations

- For more advanced mixed level ANOVAs with random effects, consult the `afex` and `lmer` packages.

- To do Bayesian versions of common hypothesis tests, try using the `BayesFactor` package. [BayesFactor Guide Link](https://cran.r-project.org/web/packages/BayesFactor/vignettes/manual.html)
